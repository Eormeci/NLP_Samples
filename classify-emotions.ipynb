{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1085454,"sourceType":"datasetVersion","datasetId":605165}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport warnings\nwarnings.filterwarnings('ignore')\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-17T17:17:28.207243Z","iopub.execute_input":"2024-03-17T17:17:28.207659Z","iopub.status.idle":"2024-03-17T17:17:28.216412Z","shell.execute_reply.started":"2024-03-17T17:17:28.207628Z","shell.execute_reply":"2024-03-17T17:17:28.215451Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"/kaggle/input/emotions-dataset-for-nlp/val.txt\n/kaggle/input/emotions-dataset-for-nlp/test.txt\n/kaggle/input/emotions-dataset-for-nlp/train.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers\n","metadata":{"execution":{"iopub.status.busy":"2024-03-17T17:17:28.218292Z","iopub.execute_input":"2024-03-17T17:17:28.218581Z","iopub.status.idle":"2024-03-17T17:17:40.844516Z","shell.execute_reply.started":"2024-03-17T17:17:28.218557Z","shell.execute_reply":"2024-03-17T17:17:40.843260Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.38.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nimport torch.nn.functional as F\nfrom transformers import BertTokenizer, BertConfig,AdamW, BertForSequenceClassification,get_linear_schedule_with_warmup\n\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix,classification_report\n# Import and evaluate each test batch using Matthew's correlation coefficient\nfrom sklearn.metrics import accuracy_score,matthews_corrcoef\n\nfrom tqdm import tqdm, trange,tnrange,tqdm_notebook\nimport random\nimport os\nimport io\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2024-03-17T17:17:40.846013Z","iopub.execute_input":"2024-03-17T17:17:40.846391Z","iopub.status.idle":"2024-03-17T17:17:40.858214Z","shell.execute_reply.started":"2024-03-17T17:17:40.846358Z","shell.execute_reply":"2024-03-17T17:17:40.857095Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nn_gpu = torch.cuda.device_count()\n#torch.cuda.get_device_name(0)\n\nSEED = 19\n\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif device == torch.device(\"cuda\"):\n    torch.cuda.manual_seed_all(SEED)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T17:17:40.859521Z","iopub.execute_input":"2024-03-17T17:17:40.859824Z","iopub.status.idle":"2024-03-17T17:17:40.927011Z","shell.execute_reply.started":"2024-03-17T17:17:40.859798Z","shell.execute_reply":"2024-03-17T17:17:40.926143Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/emotions-dataset-for-nlp/train.txt\", delimiter=';', header=None, names=['sentence','label'])\ndf_test = pd.read_csv(\"/kaggle/input/emotions-dataset-for-nlp/test.txt\", delimiter=';', header=None, names=['sentence','label'])\ndf_val = pd.read_csv(\"/kaggle/input/emotions-dataset-for-nlp/val.txt\", delimiter=';', header=None, names=['sentence','label'])","metadata":{"execution":{"iopub.status.busy":"2024-03-17T17:17:40.929699Z","iopub.execute_input":"2024-03-17T17:17:40.930020Z","iopub.status.idle":"2024-03-17T17:17:41.025424Z","shell.execute_reply.started":"2024-03-17T17:17:40.929995Z","shell.execute_reply":"2024-03-17T17:17:41.024262Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T17:17:41.026796Z","iopub.execute_input":"2024-03-17T17:17:41.027255Z","iopub.status.idle":"2024-03-17T17:17:41.045321Z","shell.execute_reply.started":"2024-03-17T17:17:41.027207Z","shell.execute_reply":"2024-03-17T17:17:41.044469Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                            sentence    label\n0                            i didnt feel humiliated  sadness\n1  i can go from feeling so hopeless to so damned...  sadness\n2   im grabbing a minute to post i feel greedy wrong    anger\n3  i am ever feeling nostalgic about the fireplac...     love\n4                               i am feeling grouchy    anger","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>i didnt feel humiliated</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i can go from feeling so hopeless to so damned...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>im grabbing a minute to post i feel greedy wrong</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i am ever feeling nostalgic about the fireplac...</td>\n      <td>love</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>i am feeling grouchy</td>\n      <td>anger</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = pd.concat([df_train,df_test,df_val])\ndf","metadata":{"execution":{"iopub.status.busy":"2024-03-17T17:17:41.046556Z","iopub.execute_input":"2024-03-17T17:17:41.047242Z","iopub.status.idle":"2024-03-17T17:17:41.062139Z","shell.execute_reply.started":"2024-03-17T17:17:41.047206Z","shell.execute_reply":"2024-03-17T17:17:41.061205Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                               sentence    label\n0                               i didnt feel humiliated  sadness\n1     i can go from feeling so hopeless to so damned...  sadness\n2      im grabbing a minute to post i feel greedy wrong    anger\n3     i am ever feeling nostalgic about the fireplac...     love\n4                                  i am feeling grouchy    anger\n...                                                 ...      ...\n1995  im having ssa examination tomorrow in the morn...  sadness\n1996  i constantly worry about their fight against n...      joy\n1997  i feel its important to share this info for th...      joy\n1998  i truly feel that if you are passionate enough...      joy\n1999  i feel like i just wanna buy any cute make up ...      joy\n\n[20000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>i didnt feel humiliated</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i can go from feeling so hopeless to so damned...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>im grabbing a minute to post i feel greedy wrong</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i am ever feeling nostalgic about the fireplac...</td>\n      <td>love</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>i am feeling grouchy</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>im having ssa examination tomorrow in the morn...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>i constantly worry about their fight against n...</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>i feel its important to share this info for th...</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>i truly feel that if you are passionate enough...</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>i feel like i just wanna buy any cute make up ...</td>\n      <td>joy</td>\n    </tr>\n  </tbody>\n</table>\n<p>20000 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Labellar","metadata":{}},{"cell_type":"code","source":"df['label'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T17:17:41.063289Z","iopub.execute_input":"2024-03-17T17:17:41.063624Z","iopub.status.idle":"2024-03-17T17:17:41.076198Z","shell.execute_reply.started":"2024-03-17T17:17:41.063593Z","shell.execute_reply":"2024-03-17T17:17:41.075304Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"array(['sadness', 'anger', 'love', 'surprise', 'fear', 'joy'],\n      dtype=object)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Labelları integer değerlere dönüştürdüm.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()\ndf['label_enc'] = labelencoder.fit_transform(df['label'])\ndf['label_enc']","metadata":{"execution":{"iopub.status.busy":"2024-03-17T17:17:41.077349Z","iopub.execute_input":"2024-03-17T17:17:41.077688Z","iopub.status.idle":"2024-03-17T17:17:41.092993Z","shell.execute_reply.started":"2024-03-17T17:17:41.077656Z","shell.execute_reply":"2024-03-17T17:17:41.092113Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"0       4\n1       4\n2       0\n3       3\n4       0\n       ..\n1995    4\n1996    2\n1997    2\n1998    2\n1999    2\nName: label_enc, Length: 20000, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"# Etiketlerin karşılıkları","metadata":{}},{"cell_type":"code","source":"df[['label','label_enc']].drop_duplicates(keep='first')","metadata":{"execution":{"iopub.status.busy":"2024-03-17T17:17:41.094261Z","iopub.execute_input":"2024-03-17T17:17:41.094584Z","iopub.status.idle":"2024-03-17T17:17:41.116021Z","shell.execute_reply.started":"2024-03-17T17:17:41.094558Z","shell.execute_reply":"2024-03-17T17:17:41.115036Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"      label  label_enc\n0   sadness          4\n2     anger          0\n3      love          3\n6  surprise          5\n7      fear          1\n8       joy          2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>label_enc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sadness</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>anger</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>love</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>surprise</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>fear</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>joy</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.rename(columns={'label':'label_desc'},inplace=True)\ndf.rename(columns={'label_enc':'label'},inplace=True)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T17:17:41.117087Z","iopub.execute_input":"2024-03-17T17:17:41.117373Z","iopub.status.idle":"2024-03-17T17:17:41.127677Z","shell.execute_reply.started":"2024-03-17T17:17:41.117350Z","shell.execute_reply":"2024-03-17T17:17:41.126680Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                                            sentence label_desc  label\n0                            i didnt feel humiliated    sadness      4\n1  i can go from feeling so hopeless to so damned...    sadness      4\n2   im grabbing a minute to post i feel greedy wrong      anger      0\n3  i am ever feeling nostalgic about the fireplac...       love      3\n4                               i am feeling grouchy      anger      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>label_desc</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>i didnt feel humiliated</td>\n      <td>sadness</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i can go from feeling so hopeless to so damned...</td>\n      <td>sadness</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>im grabbing a minute to post i feel greedy wrong</td>\n      <td>anger</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i am ever feeling nostalgic about the fireplac...</td>\n      <td>love</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>i am feeling grouchy</td>\n      <td>anger</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sentences = df.sentence.values\n\n# emoji ve tweet sayısı\nprint(\"Distribution of data based on labels: \",df.label.value_counts())\n\nMAX_LEN = 256\n\n# Bert kütüphanesini import ettim.\n# Max 256 kelime olacak şekilde tokenize ediyor.\n# input_ids = Her cümlenin tokenize edilmiş halini oluşturur.\n# truncation = kırpma işlemi\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True,truncation=True)\ninput_ids = [tokenizer.encode(sent, add_special_tokens=True,max_length=MAX_LEN,pad_to_max_length=True) for sent in sentences]\nlabels = df.label.values\n\nprint(\"Actual sentence before tokenization: \",sentences[2])\nprint(\"Encoded Input from dataset: \",input_ids[2])\n","metadata":{"execution":{"iopub.status.busy":"2024-03-17T17:17:41.128763Z","iopub.execute_input":"2024-03-17T17:17:41.129016Z","iopub.status.idle":"2024-03-17T17:17:57.696108Z","shell.execute_reply.started":"2024-03-17T17:17:41.128994Z","shell.execute_reply":"2024-03-17T17:17:57.695122Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Distribution of data based on labels:  label\n2    6761\n4    5797\n0    2709\n1    2373\n3    1641\n5     719\nName: count, dtype: int64\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"917c430d982b474f8cd481f46c13f965"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8756c37a1cc4aa985eed8038c01f3d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bb48b233b534fd5887bcc29edd3faa3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26d54a22591e42bba35d0e9cccba60f4"}},"metadata":{}},{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","output_type":"stream"},{"name":"stdout","text":"Actual sentence before tokenization:  im grabbing a minute to post i feel greedy wrong\nEncoded Input from dataset:  [101, 10047, 9775, 1037, 3371, 2000, 2695, 1045, 2514, 20505, 3308, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","output_type":"stream"}]},{"cell_type":"code","source":"# attention_mask = Modelin girdi dizisinde hangi kısımların dikkate alınacağını belirler.\n\nattention_masks = []\n\nattention_masks = [[float(i>0) for i in seq] for seq in input_ids]\nprint(attention_masks[2])","metadata":{"execution":{"iopub.status.busy":"2024-03-17T17:17:57.697464Z","iopub.execute_input":"2024-03-17T17:17:57.697787Z","iopub.status.idle":"2024-03-17T17:17:58.326779Z","shell.execute_reply.started":"2024-03-17T17:17:57.697759Z","shell.execute_reply":"2024-03-17T17:17:58.325850Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","output_type":"stream"}]},{"cell_type":"code","source":"train_inputs,validation_inputs,train_labels,validation_labels = train_test_split(\n    input_ids,labels,random_state=41,test_size=0.1)\ntrain_masks,validation_masks,_,_ = train_test_split(\n    attention_masks,input_ids,random_state=41,test_size=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T17:17:58.331196Z","iopub.execute_input":"2024-03-17T17:17:58.331490Z","iopub.status.idle":"2024-03-17T17:17:58.355806Z","shell.execute_reply.started":"2024-03-17T17:17:58.331465Z","shell.execute_reply":"2024-03-17T17:17:58.354798Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Datayı pytorch tensorlarına dönüştürüyoruz.\n#PyTorch tensorları, PyTorch kütüphanesinde temel veri yapısıdır ve çok boyutlu dizileri temsil eder.\ntrain_inputs = torch.tensor(train_inputs)\nvalidation_inputs = torch.tensor(validation_inputs)\ntrain_labels = torch.tensor(train_labels)\nvalidation_labels = torch.tensor(validation_labels)\ntrain_masks = torch.tensor(train_masks)\nvalidation_masks = torch.tensor(validation_masks)\n\nbatch_size = 32\n\ntrain_data = TensorDataset(train_inputs,train_masks,train_labels)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data,sampler=train_sampler,batch_size=batch_size)\n\nvalidation_data = TensorDataset(validation_inputs,validation_masks,validation_labels)\nvalidation_sampler = RandomSampler(validation_data)\nvalidation_dataloader = DataLoader(validation_data,sampler=validation_sampler,batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T17:17:58.356958Z","iopub.execute_input":"2024-03-17T17:17:58.357305Z","iopub.status.idle":"2024-03-17T17:18:01.502461Z","shell.execute_reply.started":"2024-03-17T17:17:58.357274Z","shell.execute_reply":"2024-03-17T17:18:01.501541Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train_data[0]","metadata":{"execution":{"iopub.status.busy":"2024-03-17T17:18:01.503608Z","iopub.execute_input":"2024-03-17T17:18:01.503932Z","iopub.status.idle":"2024-03-17T17:18:01.575175Z","shell.execute_reply.started":"2024-03-17T17:18:01.503903Z","shell.execute_reply":"2024-03-17T17:18:01.574092Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"(tensor([ 101, 1045, 2123, 1056, 2514, 2061, 9069, 2035, 1996, 2051,  102,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0]),\n tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0.]),\n tensor(4))"},"metadata":{}}]},{"cell_type":"code","source":"type(train_dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T17:18:01.576376Z","iopub.execute_input":"2024-03-17T17:18:01.576704Z","iopub.status.idle":"2024-03-17T17:18:01.584708Z","shell.execute_reply.started":"2024-03-17T17:18:01.576676Z","shell.execute_reply":"2024-03-17T17:18:01.583748Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"torch.utils.data.dataloader.DataLoader"},"metadata":{}}]},{"cell_type":"code","source":"# BertForSequenceClassification modelini yükledim.\nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=6).to(device)\n\nlr = 2e-5\nadam_epsilon = 1e-8\n\nepochs = 1\n\nnum_warmup_steps = 0\nnum_training_steps = len(train_dataloader)*epochs\n\noptimizer = AdamW(model.parameters(), lr=lr,eps=adam_epsilon,correct_bias=False)  # To reproduce BertAdam specific behavior set correct_bias=False\nscheduler = get_linear_schedule_with_warmup(\n    optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)  # PyTorch scheduler\n","metadata":{"execution":{"iopub.status.busy":"2024-03-17T17:18:01.585912Z","iopub.execute_input":"2024-03-17T17:18:01.586246Z","iopub.status.idle":"2024-03-17T17:18:05.072886Z","shell.execute_reply.started":"2024-03-17T17:18:01.586218Z","shell.execute_reply":"2024-03-17T17:18:05.072117Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62bd669e70dd417f9163923a2e21ff5e"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_loss_set = []\nlearning_rate = []\n\nmodel.zero_grad()\n\nfor _ in tnrange(1,epochs+1,desc='Epoch'):\n  print(\"<\" + \"=\"*22 + F\" Epoch {_} \"+ \"=\"*22 + \">\")\n  batch_loss = 0\n\n  for step, batch in enumerate(train_dataloader):\n    \n    model.train()\n    \n  \n    batch = tuple(t.to(device) for t in batch)\n    \n    b_input_ids, b_input_mask, b_labels = batch\n\n    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n    loss = outputs[0]\n  \n    loss.backward()\n    \n    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n    \n    optimizer.step()\n    \n    scheduler.step()\n\n    optimizer.zero_grad()\n    \n    batch_loss += loss.item()\n\n  avg_train_loss = batch_loss / len(train_dataloader)\n\n  for param_group in optimizer.param_groups:\n    print(\"\\n\\tCurrent Learning rate: \",param_group['lr'])\n    learning_rate.append(param_group['lr'])\n    \n  train_loss_set.append(avg_train_loss)\n  print(F'\\n\\tAverage Training loss: {avg_train_loss}')\n    \n  model.eval()\n\n  eval_accuracy,eval_mcc_accuracy,nb_eval_steps = 0, 0, 0\n\n  for batch in validation_dataloader:\n    batch = tuple(t.to(device) for t in batch)\n    b_input_ids, b_input_mask, b_labels = batch\n    with torch.no_grad():\n\n      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n    \n    logits = logits[0].to('cpu').numpy()\n    label_ids = b_labels.to('cpu').numpy()\n\n    pred_flat = np.argmax(logits, axis=1).flatten()\n    labels_flat = label_ids.flatten()\n    \n    df_metrics=pd.DataFrame({'Epoch':epochs,'Actual_class':labels_flat,'Predicted_class':pred_flat})\n    \n    tmp_eval_accuracy = accuracy_score(labels_flat,pred_flat)\n    tmp_eval_mcc_accuracy = matthews_corrcoef(labels_flat, pred_flat)\n    \n    eval_accuracy += tmp_eval_accuracy\n    eval_mcc_accuracy += tmp_eval_mcc_accuracy\n    nb_eval_steps += 1\n\n  print(F'\\n\\tValidation Accuracy: {eval_accuracy/nb_eval_steps}')\n  print(F'\\n\\tValidation MCC Accuracy: {eval_mcc_accuracy/nb_eval_steps}')","metadata":{"execution":{"iopub.status.busy":"2024-03-17T17:18:05.074052Z","iopub.execute_input":"2024-03-17T17:18:05.074416Z","iopub.status.idle":"2024-03-17T17:30:26.835701Z","shell.execute_reply.started":"2024-03-17T17:18:05.074383Z","shell.execute_reply":"2024-03-17T17:30:26.834618Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"417fd2afe695449b8692fe6e6ba876e2"}},"metadata":{}},{"name":"stdout","text":"<====================== Epoch 1 ======================>\n\n\tCurrent Learning rate:  0.0\n\n\tAverage Training loss: 0.35985879322140085\n\n\tValidation Accuracy: 0.9285714285714286\n\n\tValidation MCC Accuracy: 0.9068632336252975\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,classification_report\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n\n    import itertools\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T17:30:26.837079Z","iopub.execute_input":"2024-03-17T17:30:26.837422Z","iopub.status.idle":"2024-03-17T17:30:26.848252Z","shell.execute_reply.started":"2024-03-17T17:30:26.837393Z","shell.execute_reply":"2024-03-17T17:30:26.847166Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"df[['label','label_desc']].drop_duplicates(keep='first')","metadata":{"execution":{"iopub.status.busy":"2024-03-17T17:30:26.849624Z","iopub.execute_input":"2024-03-17T17:30:26.849977Z","iopub.status.idle":"2024-03-17T17:30:26.877286Z","shell.execute_reply.started":"2024-03-17T17:30:26.849945Z","shell.execute_reply":"2024-03-17T17:30:26.876395Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"   label label_desc\n0      4    sadness\n2      0      anger\n3      3       love\n6      5   surprise\n7      1       fear\n8      2        joy","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>label_desc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>love</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>5</td>\n      <td>surprise</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>fear</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2</td>\n      <td>joy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"label2int = {\n  \"sadness\": 4,\n  \"joy\": 2,\n  \"anger\": 0,\n  \"fear\": 1,\n  \"surprise\": 5\n}","metadata":{"execution":{"iopub.status.busy":"2024-03-17T17:30:26.878470Z","iopub.execute_input":"2024-03-17T17:30:26.878817Z","iopub.status.idle":"2024-03-17T17:30:26.883734Z","shell.execute_reply.started":"2024-03-17T17:30:26.878785Z","shell.execute_reply":"2024-03-17T17:30:26.882802Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"df_metrics['Predicted_class'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T17:30:26.884947Z","iopub.execute_input":"2024-03-17T17:30:26.885947Z","iopub.status.idle":"2024-03-17T17:30:26.903740Z","shell.execute_reply.started":"2024-03-17T17:30:26.885912Z","shell.execute_reply":"2024-03-17T17:30:26.902751Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"array([4, 3, 2, 1, 0])"},"metadata":{}}]},{"cell_type":"code","source":"print(classification_report(df_metrics['Actual_class'].values, df_metrics['Predicted_class'].values, target_names=label2int.keys(), digits=len(label2int)))","metadata":{"execution":{"iopub.status.busy":"2024-03-17T17:32:13.656881Z","iopub.execute_input":"2024-03-17T17:32:13.657661Z","iopub.status.idle":"2024-03-17T17:32:13.672710Z","shell.execute_reply.started":"2024-03-17T17:32:13.657626Z","shell.execute_reply":"2024-03-17T17:32:13.671712Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n     sadness    1.00000   1.00000   1.00000         2\n         joy    1.00000   1.00000   1.00000         1\n       anger    1.00000   1.00000   1.00000         5\n        fear    1.00000   1.00000   1.00000         3\n    surprise    1.00000   1.00000   1.00000         5\n\n    accuracy                        1.00000        16\n   macro avg    1.00000   1.00000   1.00000        16\nweighted avg    1.00000   1.00000   1.00000        16\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model_save_folder = 'model/'\ntokenizer_save_folder = 'tokenizer/'\n\npath_model = 'kaggle/working/' + model_save_folder\npath_tokenizer = 'kaggle/working/' + tokenizer_save_folder\n\n##create the dir\n\n!mkdir -p {path_model}\n!mkdir -p {path_tokenizer}\n\n### Now let's save our model and tokenizer to a directory\nmodel.save_pretrained(path_model)\ntokenizer.save_pretrained(path_tokenizer)\n\nmodel_save_name = 'model.pt'\npath = path_model + model_save_name\ntorch.save(model.state_dict(), path)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-17T17:40:49.319207Z","iopub.execute_input":"2024-03-17T17:40:49.319545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}